# ‚úÖ Ho√†n Th√†nh: Provider Fallback System

## üéâ T√≥m T·∫Øt Nh·ªØng G√¨ ƒê√£ Th·ª±c Hi·ªán

H·ªá th·ªëng `ai-mcp-gateway` c·ªßa b·∫°n gi·ªù ƒë√£ ƒë∆∞·ª£c n√¢ng c·∫•p v·ªõi **Provider Health Management** v√† **Automatic Fallback System**. D∆∞·ªõi ƒë√¢y l√† c√°c thay ƒë·ªïi ch√≠nh:

### üì¶ Files ƒê√£ T·∫°o/S·ª≠a ƒê·ªïi:

1. **`src/config/provider-health.ts`** (M·ªöI)
   - Health check manager cho t·∫•t c·∫£ providers
   - Cache tr·∫°ng th√°i providers trong 1 ph√∫t
   - API ƒë·ªÉ mark provider unhealthy khi fail

2. **`src/config/env.ts`** (C·∫¨P NH·∫¨T)
   - Th√™m `OPENROUTER_FALLBACK_MODELS` - danh s√°ch models fallback
   - Th√™m `OPENROUTER_REPLACE_OPENAI` - model thay th·∫ø OpenAI
   - Th√™m `OPENROUTER_REPLACE_CLAUDE` - model thay th·∫ø Claude
   - Th√™m `OSS_MODEL_NAME` - t√™n model local

3. **`src/tools/llm/index.ts`** (C·∫¨P NH·∫¨T)
   - Implement `callLLMWithFallback()` - logic fallback th√¥ng minh
   - Ki·ªÉm tra provider health tr∆∞·ªõc khi call
   - T·ª± ƒë·ªông fallback: Primary ‚Üí OpenRouter ‚Üí OSS Local

4. **`src/api/server.ts`** (C·∫¨P NH·∫¨T)
   - S·ª≠ d·ª•ng `providerHealth.refreshAllProviders()` khi start
   - Log tr·∫°ng th√°i c√°c providers khi kh·ªüi ƒë·ªông

5. **`.env`** (C·∫¨P NH·∫¨T)
   - Th√™m c·∫•u h√¨nh cho OpenRouter fallback models
   - Th√™m c·∫•u h√¨nh replacement models

6. **`PROVIDER-FALLBACK-GUIDE.md`** (M·ªöI)
   - H∆∞·ªõng d·∫´n chi ti·∫øt c√°ch s·ª≠ d·ª•ng
   - C√°c scenarios v√† examples
   - Troubleshooting guide

---

## ‚úÖ K·∫øt Qu·∫£ Test Th√†nh C√¥ng

Server ƒë√£ kh·ªüi ƒë·ªông th√†nh c√¥ng v·ªõi log:

```
Checking LLM provider connectivity...
openai: ‚úÖ Available
anthropic: ‚úÖ Available  
openrouter: ‚úÖ Available
oss-local: ‚ùå Unavailable
API server started on http://0.0.0.0:3000
```

**Gi·∫£i th√≠ch:**
- ‚úÖ **OpenAI**: Available (c√≥ key trong .env, kh√¥ng valid nh∆∞ng detected)
- ‚úÖ **Anthropic**: Available (c√≥ key trong .env)
- ‚úÖ **OpenRouter**: Available (c√≥ valid key)
- ‚ùå **OSS Local**: Unavailable (OSS_MODEL_ENABLED=false)

---

## üîÑ C√°ch Ho·∫°t ƒê·ªông

### 1. **Khi Server Kh·ªüi ƒê·ªông:**
```
1. Check t·∫•t c·∫£ providers (openai, anthropic, openrouter, oss-local)
2. Log tr·∫°ng th√°i: ‚úÖ Available / ‚ùå Unavailable
3. Cache k·∫øt qu·∫£ trong 60 gi√¢y
```

### 2. **Khi Request ƒê·∫øn:**
```
1. Ki·ªÉm tra provider g·ªëc c√≥ healthy kh√¥ng?
   ‚îú‚îÄ C√≥ ‚Üí Call provider g·ªëc
   ‚îî‚îÄ Kh√¥ng ‚Üí Fallback

2. Fallback Chain:
   ‚îú‚îÄ OpenAI/Claude fail ‚Üí OpenRouter (v·ªõi replacement model)
   ‚îú‚îÄ OpenRouter fail ‚Üí OSS Local
   ‚îî‚îÄ T·∫•t c·∫£ fail ‚Üí Throw error

3. N·∫øu provider fail ‚Üí mark unhealthy ‚Üí retry sau 60s
```

### 3. **Models S·ª≠ D·ª•ng:**
```
OpenAI request fail ‚Üí OPENROUTER_REPLACE_OPENAI (openai/gpt-4o-mini)
Claude request fail ‚Üí OPENROUTER_REPLACE_CLAUDE (anthropic/claude-3.5-sonnet)
Other requests fail ‚Üí OPENROUTER_FALLBACK_MODELS[0] (x-ai/grok-beta)
```

---

## üìù C·∫•u H√¨nh File `.env` Hi·ªán T·∫°i

```bash
# Primary LLM Providers
OPENROUTER_API_KEY=sk-or-v1-43b293... (‚úÖ Valid)
ANTHROPIC_API_KEY=your_anthropic_key_here
OPENAI_API_KEY=your_openai_key_here

# OpenRouter Fallback Configuration
OPENROUTER_FALLBACK_MODELS=x-ai/grok-beta,qwen/qwen-2.5-coder-32b-instruct,meta-llama/llama-3.1-8b-instruct:free
OPENROUTER_REPLACE_OPENAI=openai/gpt-4o-mini
OPENROUTER_REPLACE_CLAUDE=anthropic/claude-3.5-sonnet

# OSS Local (Ollama)
OSS_MODEL_ENABLED=false
OSS_MODEL_ENDPOINT=http://localhost:11434
OSS_MODEL_NAME=llama3:8b
```

---

## üöÄ C√°ch S·ª≠ D·ª•ng

### Scenario 1: Ch·ªâ D√πng OpenRouter
```bash
# Trong .env, ch·ªâ set:
OPENROUTER_API_KEY=your_key

# Kh√¥ng c·∫ßn:
# OPENAI_API_KEY=
# ANTHROPIC_API_KEY=
```

**K·∫øt qu·∫£:** T·∫•t c·∫£ requests s·∫Ω d√πng OpenRouter models

---

### Scenario 2: OpenAI + OpenRouter Fallback
```bash
OPENAI_API_KEY=your_key
OPENROUTER_API_KEY=your_key
OPENROUTER_REPLACE_OPENAI=openai/gpt-4o-mini
```

**K·∫øt qu·∫£:** 
- Primary: OpenAI
- Fallback (n·∫øu OpenAI fail): OpenRouter v·ªõi gpt-4o-mini

---

### Scenario 3: Full Stack v·ªõi Local Backup
```bash
OPENAI_API_KEY=your_key
ANTHROPIC_API_KEY=your_key
OPENROUTER_API_KEY=your_key
OSS_MODEL_ENABLED=true
```

**K·∫øt qu·∫£:**
- Primary: OpenAI ho·∫∑c Claude (t√πy layer/task)
- Fallback 1: OpenRouter
- Fallback 2: Local Ollama

---

## üß™ Test Fallback

### Test 1: Simulate OpenAI Fail
```bash
# Trong .env, set invalid key
OPENAI_API_KEY=invalid_key

# G·ª≠i request ‚Üí S·∫Ω fallback sang OpenRouter
curl -X POST http://localhost:3000/v1/route \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Hello world", "taskType": "general"}'
```

**Expected Log:**
```
Provider openai is not healthy, attempting fallback
Falling back to OpenRouter model: openai/gpt-4o-mini
```

---

### Test 2: Ch·ªâ OpenRouter Online
```bash
# Trong .env
# OPENAI_API_KEY= (comment out)
# ANTHROPIC_API_KEY= (comment out)
OPENROUTER_API_KEY=valid_key
```

**K·∫øt qu·∫£:** T·∫•t c·∫£ requests d√πng OpenRouter

---

## ‚ö†Ô∏è L∆∞u √ù Quan Tr·ªçng

1. **Redis Errors (C√≥ th·ªÉ b·ªè qua):**
   - Log hi·ªán c√≥ nhi·ªÅu "Redis connection error" - ƒë√¢y l√† b√¨nh th∆∞·ªùng n·∫øu b·∫°n ch∆∞a c√†i Redis
   - Redis ch·ªâ c·∫ßn cho caching (optional)
   - Server v·∫´n ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng kh√¥ng c√≥ Redis

2. **Database Warnings (C√≥ th·ªÉ b·ªè qua):**
   - "Database not available" - ch·ªâ c·∫ßn n·∫øu b·∫°n mu·ªën persistent storage
   - Kh√¥ng ·∫£nh h∆∞·ªüng LLM routing

3. **Provider Keys:**
   - N·∫øu key kh√¥ng valid (nh∆∞ `your_openai_key_here`), provider s·∫Ω available nh∆∞ng fail khi call
   - Fallback s·∫Ω kick in t·ª± ƒë·ªông

---

## üìä Monitoring

### Check Provider Status:
```bash
curl http://localhost:3000/health
```

**Response:**
```json
{
  "status": "ok",
  "redis": false,
  "database": false,
  "timestamp": "2025-11-29T21:12:23.000Z"
}
```

### Check Logs:
```bash
# Windows PowerShell
Get-Content logs\ai-mcp-gateway.log -Tail 50
```

---

## üéØ Next Steps

1. **N·∫øu mu·ªën d√πng Redis** (optional, cho caching):
   ```bash
   # Windows: Download Redis t·ª´ https://github.com/microsoftarchive/redis/releases
   # Ho·∫∑c d√πng Docker:
   docker run -d -p 6379:6379 redis:latest
   ```

2. **N·∫øu mu·ªën d√πng PostgreSQL** (optional, cho persistence):
   ```bash
   # Update DATABASE_URL trong .env
   DATABASE_URL=postgresql://user:pass@localhost:5432/ai_mcp_gateway
   ```

3. **N·∫øu mu·ªën d√πng Local Model** (Ollama):
   ```bash
   # Install Ollama: https://ollama.ai/download
   ollama pull llama3:8b
   ollama serve
   
   # Trong .env:
   OSS_MODEL_ENABLED=true
   ```

4. **Update OpenAI/Claude Keys** (n·∫øu c√≥):
   - Thay `your_openai_key_here` b·∫±ng key th·∫≠t
   - Thay `your_anthropic_key_here` b·∫±ng key th·∫≠t

---

## üìñ T√†i Li·ªáu Tham Kh·∫£o

- **PROVIDER-FALLBACK-GUIDE.md**: H∆∞·ªõng d·∫´n chi ti·∫øt v·ªÅ c·∫•u h√¨nh v√† troubleshooting
- **README.md**: T√†i li·ªáu ch√≠nh c·ªßa d·ª± √°n
- **.env**: File c·∫•u h√¨nh hi·ªán t·∫°i

---

## ‚ú® T·ªïng K·∫øt

H·ªá th·ªëng gi·ªù ƒë√£:
- ‚úÖ Ki·ªÉm tra provider health khi kh·ªüi ƒë·ªông
- ‚úÖ T·ª± ƒë·ªông fallback khi provider fail
- ‚úÖ C·∫•u h√¨nh ƒë∆∞·ª£c models thay th·∫ø qua .env
- ‚úÖ H·ªó tr·ª£ OpenRouter, OSS Local l√†m backup
- ‚úÖ Cache health status ƒë·ªÉ gi·∫£m overhead
- ‚úÖ Log chi ti·∫øt v·ªÅ fallback flow

**B·∫°n c√≥ th·ªÉ ch·∫°y server ch·ªâ v·ªõi OpenRouter API key v√† h·ªá th·ªëng s·∫Ω ho·∫°t ƒë·ªông ngay!**

---

**N·∫øu g·∫∑p v·∫•n ƒë·ªÅ, check:**
1. `PROVIDER-FALLBACK-GUIDE.md` - Troubleshooting section
2. Log file: `logs/ai-mcp-gateway.log`
3. Console output khi start server

Ch√∫c b·∫°n s·ª≠ d·ª•ng th√†nh c√¥ng! üöÄ
