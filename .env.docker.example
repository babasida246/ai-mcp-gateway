# AI MCP Gateway - Environment Variables
# Copy this file to .env.docker and customize with your values

# ============================================
# LLM Provider API Keys
# ============================================
# REQUIRED: At least one provider API key
OPENROUTER_API_KEY=your_openrouter_api_key_here
# OPENAI_API_KEY=your_openai_api_key_here
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# ============================================
# OpenRouter Configuration
# ============================================
OPENROUTER_FALLBACK_MODELS=x-ai/grok-beta,qwen/qwen-2.5-coder-32b-instruct,meta-llama/llama-3.1-8b-instruct:free
OPENROUTER_REPLACE_OPENAI=openai/gpt-4o-mini
OPENROUTER_REPLACE_CLAUDE=anthropic/claude-3.5-sonnet

# ============================================
# OSS/Local Model (Ollama)
# ============================================
# Set to true if using Ollama (requires: docker-compose --profile with-ollama up)
OSS_MODEL_ENABLED=false
OSS_MODEL_ENDPOINT=http://ollama:11434
OSS_MODEL_NAME=llama3:8b

# ============================================
# Database (PostgreSQL)
# ============================================
POSTGRES_DB=ai_mcp_gateway
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_secure_postgres_password_here

# ============================================
# Redis Cache
# ============================================
# Leave empty for no password (development only)
REDIS_PASSWORD=

# ============================================
# Application Configuration
# ============================================
LOG_LEVEL=info
DEFAULT_LAYER=L0
ENABLE_CROSS_CHECK=true
ENABLE_AUTO_ESCALATE=true
MAX_ESCALATION_LAYER=L2
ENABLE_COST_TRACKING=true
COST_ALERT_THRESHOLD=1.00
